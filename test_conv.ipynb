{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee8d63fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[251., 474., 386.],\n",
       "          [498., 855., 498.],\n",
       "          [386., 474., 251.]],\n",
       "\n",
       "         [[251., 474., 386.],\n",
       "          [498., 855., 498.],\n",
       "          [386., 474., 251.]],\n",
       "\n",
       "         [[251., 474., 386.],\n",
       "          [498., 855., 498.],\n",
       "          [386., 474., 251.]]]], grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "conv = torch.nn.Conv2d(3, 3, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "# change parameter of conv\n",
    "\n",
    "\n",
    "input_tensor = torch.tensor([\n",
    "    [[1.0, 2.0, 3.0],\n",
    "    [4.0, 5.0, 6.0],\n",
    "    [7.0, 8.0, 9.0]],\n",
    "\n",
    "    [[2.0, 3.0, 4.0],\n",
    "    [5.0, 6.0, 7.0],\n",
    "    [8.0, 9.0, 1.0]],\n",
    "\n",
    "    [[3.0, 4.0, 5.0],\n",
    "    [6.0, 7.0, 8.0],\n",
    "    [9.0, 1.0, 2.0]],\n",
    "\n",
    "\n",
    "    \n",
    "    ])\n",
    "\n",
    "print(input_tensor.shape)\n",
    "conv.weight = torch.nn.Parameter(torch.tensor([[\n",
    "    [[1.0, 2.0, 3.0],\n",
    "    [4.0, 5.0, 6.0],\n",
    "    [7.0, 8.0, 9.0]],\n",
    "\n",
    "    [[2.0, 3.0, 4.0],\n",
    "    [5.0, 6.0, 7.0],\n",
    "    [8.0, 9.0, 1.0]],\n",
    "\n",
    "    [[3.0, 4.0, 5.0],\n",
    "    [6.0, 7.0, 8.0],\n",
    "    [9.0, 1.0, 2.0]],\n",
    "\n",
    "],\n",
    "[\n",
    "    [[1.0, 2.0, 3.0],\n",
    "    [4.0, 5.0, 6.0],\n",
    "    [7.0, 8.0, 9.0]],\n",
    "\n",
    "    [[2.0, 3.0, 4.0],\n",
    "    [5.0, 6.0, 7.0],\n",
    "    [8.0, 9.0, 1.0]],\n",
    "\n",
    "    [[3.0, 4.0, 5.0],\n",
    "    [6.0, 7.0, 8.0],\n",
    "    [9.0, 1.0, 2.0]],\n",
    "\n",
    "],\n",
    "[\n",
    "    [[1.0, 2.0, 3.0],\n",
    "    [4.0, 5.0, 6.0],\n",
    "    [7.0, 8.0, 9.0]],\n",
    "\n",
    "    [[2.0, 3.0, 4.0],\n",
    "    [5.0, 6.0, 7.0],\n",
    "    [8.0, 9.0, 1.0]],\n",
    "\n",
    "    [[3.0, 4.0, 5.0],\n",
    "    [6.0, 7.0, 8.0],\n",
    "    [9.0, 1.0, 2.0]],\n",
    "\n",
    "]]))\n",
    "\n",
    "\n",
    "output = conv(input_tensor.unsqueeze(0))  # Add batch dimension\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b96ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 10, 10])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class MulMask(nn.Module):\n",
    "    def __init__(self, mask):\n",
    "        super().__init__()\n",
    "        self.register_buffer(\"mask\", mask)\n",
    "    def forward(self, W):\n",
    "        return W * self.mask\n",
    "\n",
    "\n",
    "class VisionTransformer(timm.models.vision_transformer.VisionTransformer):\n",
    "    \"\"\" Vision Transformer with support for global average pooling and custom QKV input \"\"\"\n",
    "    def __init__(self, global_pool=False, mask_ratio=0.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        ...\n",
    "        self.pred_conv = torch.nn.Conv2d(self.d_model, self.d_model, kernel_size=3, stride=1, padding=1)\n",
    "        self.weight_mask = torch.ones_like(self.pred_conv.weight)\n",
    "        self.weight_mask[..., 1, 1] = 0\n",
    "        self.register_buffer(\"weight_mask\", self.weight_mask)  # 학습X, 디바이스 이동/저장O\n",
    "\n",
    "        parametrize.register_parametrization(self.pred_conv, \"weight\", MulMask(self.weight_mask))\n",
    "\n",
    "\n",
    "    def calc_energy(self, x): # x shape: batch_num, patch_num, emb_dim\n",
    "        H, W = self.img_size\n",
    "        B, N, D = x.shape\n",
    "\n",
    "        H_p, W_p = self.patch_embed.grid_size\n",
    "        if N == 1 + H_p * W_p:\n",
    "            x = x[:, 1:, :]\n",
    "            N = H_p * W_p\n",
    "        x_2d = x.reshape(B, H_p, W_p, D).permute(0, 3, 1, 2).contiguous()\n",
    "\n",
    "        # 패치별 에너지 계산 (MAE 스타일)\n",
    "\n",
    "        out_2d = self.pred_conv(x_2d)  # (B, D, H_p, W_p)\n",
    "\n",
    "        out = out_2d.permute(0, 2, 3, 1).reshape(B, N, D)\n",
    "        energy = F.cosine_similarity(x.float(), out.float(), dim=-1)  # (B, N)\n",
    "\n",
    "        return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b691fce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 40, 40])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H, W = 40, 40\n",
    "# i+j 홀수인 마스크 생성\n",
    "i_idx = torch.arange(H).unsqueeze(1)\n",
    "j_idx = torch.arange(W).unsqueeze(0)\n",
    "mask1 = (i_idx + j_idx) % 2 == 1  # dtype: bool\n",
    "mask2 = ~mask1\n",
    "\n",
    "checker_masking = torch.stack([mask1, mask2])\n",
    "checker_masking.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26ba4a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "mask_ratio = 0.01\n",
    "true_indices = checker_masking[random.randint(0,1)].nonzero(as_tuple=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "680b0d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 1, 0, 1],\n",
       "        [1, 0, 1, 0, 1, 0],\n",
       "        [0, 1, 0, 1, 0, 1],\n",
       "        [1, 0, 1, 0, 1, 0],\n",
       "        [0, 1, 0, 1, 0, 1],\n",
       "        [1, 0, 1, 0, 1, 0]], dtype=torch.int16)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def odd_sum_flat_indices(W: int, H: int, device=None):\n",
    "    \"\"\"\n",
    "    (W, H) 격자에서 (i + j)가 홀수인 위치를\n",
    "    flatten(view(-1)) 순서(행우선, flat_idx = i*H + j) 기준으로 반환.\n",
    "\n",
    "    Returns:\n",
    "        mask_flat: (W*H,) bool  — i+j가 홀수면 True\n",
    "        idx_flat:  (K,)   long  — 위 조건을 만족하는 평탄화 인덱스\n",
    "    \"\"\"\n",
    "    device = device or \"cpu\"\n",
    "\n",
    "    # (W,H)에서 i=행(0..W-1), j=열(0..H-1)\n",
    "    i = torch.arange(W, device=device).unsqueeze(1)   # (W,1)\n",
    "    j = torch.arange(H, device=device).unsqueeze(0)   # (1,H)\n",
    "\n",
    "    # 2D 마스크: i+j가 홀수\n",
    "    odd2d = ((i + j) % 2 == 0)                        # (W,H) bool\n",
    "\n",
    "    # flatten(view) 순서로 1D 마스크/인덱스\n",
    "    mask_flat = odd2d.view(-1)                        # (W*H,)\n",
    "    idx_flat = mask_flat.nonzero(as_tuple=False).squeeze(1)   # (K,)\n",
    "    return idx_flat\n",
    "\n",
    "\n",
    "W, H = 6, 6\n",
    "\n",
    "my_data = torch.ones((W, H), dtype=torch.int16)\n",
    "idx = odd_sum_flat_indices(W, H)\n",
    "my_data_flatten = my_data.flatten()\n",
    "\n",
    "my_data_flatten[idx] = 0 \n",
    "my_data = my_data_flatten.view(W, H)  # (W, H) 형태로 복원\n",
    "my_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "73118bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 9, 4, 6, 5, 6, 0, 2, 2, 4, 6, 0, 6, 5, 6, 2, 3, 1, 3, 9, 5, 8, 3, 6,\n",
      "         0, 8, 5, 9, 9, 9, 3, 4, 3, 6, 0, 1]], dtype=torch.int16)\n",
      "tensor([[9, 6, 6, 0, 2, 6, 5, 2, 1, 3, 5, 3, 8, 9, 9, 3, 3, 0]],\n",
      "       dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "my_data = torch.randint(0, 10, (W, H), dtype=torch.int16).flatten().unsqueeze(0)\n",
    "mask_idx = odd_sum_flat_indices(W, H)\n",
    "print(my_data)\n",
    "print(my_data[:, mask_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7d6eaacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4, 8, 6, 0, 2],\n",
       "        [4, 8, 6, 0, 2]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def masked_topk(X: torch.Tensor, cand_mask: torch.Tensor, k: int, largest: bool):\n",
    "    \"\"\"\n",
    "    X: (B, N)\n",
    "    cand_mask: (B, N) 또는 (N,)  True = 후보로 포함\n",
    "    k: 뽑을 개수\n",
    "    largest: True면 상위 K, False면 하위 K\n",
    "    return: vals, idx  (둘 다 (B, k))\n",
    "    \"\"\"\n",
    "    if cand_mask.dim() == 1:\n",
    "        cand_mask = cand_mask.unsqueeze(0).expand(X.size(0), -1)\n",
    "\n",
    "    sentinel = float('-inf') if largest else float('inf')\n",
    "    X_masked = X.masked_fill(~cand_mask, sentinel)\n",
    "    vals, idx = torch.topk(X_masked, k=k, dim=1, largest=largest, sorted=True)\n",
    "    return vals, idx\n",
    "\n",
    "\n",
    "\n",
    "mask_ratio = 0.6\n",
    "keep_ratio = 1 - mask_ratio\n",
    "my_data = torch.tensor([\n",
    "    [1, 5, 2, \n",
    "     -1, 5, 6, \n",
    "     7, 8, 9],\n",
    "                        [1, 5, 2, -1, 5, 6, -7, 8, 9]])\n",
    "\n",
    "\n",
    "idx = odd_sum_flat_indices(3, 3)\n",
    "\n",
    "\n",
    "my_data_choice = my_data.clone()\n",
    "my_data_choice[:, idx] = 9999\n",
    "# my_data_choice[:, idx] = float('inf')\n",
    "\n",
    "\n",
    "_, keep_idx = torch.topk(my_data_choice, k=int((len(my_data[0]) - len(idx)) * (1 - mask_ratio*2)) + len(idx), dim=1)\n",
    "keep_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "98aa5fd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int((len(my_data) - len(idx)) * (1 - mask_ratio*2))# + len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b4c667fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 100000000,          5,  200000000,         -1,  500000000,          6,\n",
       "          700000000,          8,  900000000],\n",
       "        [ 100000000,          5,  200000000,         -1,  500000000,          6,\n",
       "         -700000000,          8,  900000000]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data[:, idx] *= 100000000\n",
    "my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7ec53b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10,  9,  8,  7,  6,  5],\n",
       "        [ 9,  8,  6,  5,  5,  2]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_data_kept = my_data.gather(1, keep_idx)  # (B, N-K)\n",
    "my_data_kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e804bb59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4, 7])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(5, 6, 7)  # (B, N, D)\n",
    "\n",
    "\n",
    "idx = torch.tensor([\n",
    "    [0, 1],\n",
    "    [2, 3]\n",
    "]) # (B, N')\n",
    "\n",
    "keep_mask = torch.zeros(len(x[1]), dtype=torch.bool)\n",
    "keep_mask[idx] = True\n",
    "\n",
    "\n",
    "\n",
    "x_ = x[:,keep_mask, :]  # (B, K, D)\n",
    "x_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "703c2956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.5404,  1.5642,  0.7286,  0.7942,  1.2502, -0.3675, -0.8182],\n",
      "         [ 0.7306,  0.2557, -0.5653,  0.0101,  0.8182,  1.1749, -0.7822],\n",
      "         [-0.5330, -0.4039,  0.7959, -3.6322,  0.7030, -1.2678,  1.2280],\n",
      "         [ 0.3460, -0.1492, -0.5937, -0.4439,  0.0613, -0.3712,  0.1414],\n",
      "         [-0.8871,  0.6600,  0.5419, -0.3703,  0.1059, -1.0887,  1.2211],\n",
      "         [ 0.5977,  1.1057, -0.2580,  0.4664, -0.8103, -0.2414, -0.9857]],\n",
      "\n",
      "        [[-0.2050, -0.3072, -1.4555,  1.0356, -1.3507, -1.2357, -1.4040],\n",
      "         [-0.8913, -1.0701,  1.0238, -0.7172,  0.9297,  0.5454, -1.8978],\n",
      "         [-0.3596,  0.5746, -1.4057, -0.8708, -0.2433, -0.8615,  1.1718],\n",
      "         [-0.0807,  0.1792, -1.0630, -0.7052, -0.1952, -0.1136, -0.0244],\n",
      "         [ 0.2372, -0.5564, -1.8119, -1.3283,  0.8437,  0.3541, -0.0890],\n",
      "         [-0.2144,  0.3791, -0.4306,  0.2335, -0.5746,  0.4505, -0.0391]],\n",
      "\n",
      "        [[-1.5534,  1.2160, -1.6798,  0.2679,  2.4092,  0.4152,  0.1347],\n",
      "         [-0.1756,  1.6643, -1.4552,  2.2137,  1.1880,  0.3037,  0.1410],\n",
      "         [-0.5269,  1.8338, -2.0599,  1.7139, -1.2064, -0.1879, -1.5944],\n",
      "         [ 1.1134,  0.6083,  0.2002, -1.0417,  1.2494, -1.1443, -2.6373],\n",
      "         [ 0.2591,  1.2457,  0.0520, -0.8158, -2.5024,  0.7542,  0.5489],\n",
      "         [-1.3954,  0.1986,  0.6463, -2.1294,  0.1681, -2.7800, -0.2029]],\n",
      "\n",
      "        [[-1.4631,  0.1591, -0.7854,  0.0742, -0.7529,  0.7044, -0.1008],\n",
      "         [-2.1103,  0.4103,  0.7679,  2.4005,  1.2916,  0.7836,  1.7508],\n",
      "         [-0.8905, -1.0503,  0.6383,  0.3689,  1.3998,  0.8443, -1.2613],\n",
      "         [-0.7677,  0.9120, -1.2449,  0.2539, -0.8253, -1.2735, -0.5176],\n",
      "         [ 0.2049, -0.1661,  1.6371,  0.7379, -2.3323, -0.8624, -0.6296],\n",
      "         [-0.2985, -2.3127, -0.6100,  0.8515, -0.5685,  1.5297,  0.4566]],\n",
      "\n",
      "        [[ 0.8322, -0.0257,  1.2946, -0.2846,  1.3474,  0.9230, -1.1019],\n",
      "         [-1.6414, -0.4609,  0.2016,  1.3620, -0.1493,  0.2126, -0.8517],\n",
      "         [-0.2152,  0.7875,  0.4160, -0.8650, -0.8026, -1.6485, -0.4947],\n",
      "         [ 0.2850, -0.5163, -0.9208,  0.6112,  0.6213,  1.4130, -0.5528],\n",
      "         [ 2.5129,  0.7887, -0.6904, -0.0836, -0.4866, -2.8712, -1.2897],\n",
      "         [ 0.5106, -0.1485, -0.9670,  0.9344, -0.4430, -1.4320,  1.3069]]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "56deeacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.5404,  1.5642,  0.7286,  0.7942,  1.2502, -0.3675, -0.8182],\n",
      "         [ 0.7306,  0.2557, -0.5653,  0.0101,  0.8182,  1.1749, -0.7822],\n",
      "         [-0.5330, -0.4039,  0.7959, -3.6322,  0.7030, -1.2678,  1.2280],\n",
      "         [ 0.3460, -0.1492, -0.5937, -0.4439,  0.0613, -0.3712,  0.1414]],\n",
      "\n",
      "        [[-0.2050, -0.3072, -1.4555,  1.0356, -1.3507, -1.2357, -1.4040],\n",
      "         [-0.8913, -1.0701,  1.0238, -0.7172,  0.9297,  0.5454, -1.8978],\n",
      "         [-0.3596,  0.5746, -1.4057, -0.8708, -0.2433, -0.8615,  1.1718],\n",
      "         [-0.0807,  0.1792, -1.0630, -0.7052, -0.1952, -0.1136, -0.0244]],\n",
      "\n",
      "        [[-1.5534,  1.2160, -1.6798,  0.2679,  2.4092,  0.4152,  0.1347],\n",
      "         [-0.1756,  1.6643, -1.4552,  2.2137,  1.1880,  0.3037,  0.1410],\n",
      "         [-0.5269,  1.8338, -2.0599,  1.7139, -1.2064, -0.1879, -1.5944],\n",
      "         [ 1.1134,  0.6083,  0.2002, -1.0417,  1.2494, -1.1443, -2.6373]],\n",
      "\n",
      "        [[-1.4631,  0.1591, -0.7854,  0.0742, -0.7529,  0.7044, -0.1008],\n",
      "         [-2.1103,  0.4103,  0.7679,  2.4005,  1.2916,  0.7836,  1.7508],\n",
      "         [-0.8905, -1.0503,  0.6383,  0.3689,  1.3998,  0.8443, -1.2613],\n",
      "         [-0.7677,  0.9120, -1.2449,  0.2539, -0.8253, -1.2735, -0.5176]],\n",
      "\n",
      "        [[ 0.8322, -0.0257,  1.2946, -0.2846,  1.3474,  0.9230, -1.1019],\n",
      "         [-1.6414, -0.4609,  0.2016,  1.3620, -0.1493,  0.2126, -0.8517],\n",
      "         [-0.2152,  0.7875,  0.4160, -0.8650, -0.8026, -1.6485, -0.4947],\n",
      "         [ 0.2850, -0.5163, -0.9208,  0.6112,  0.6213,  1.4130, -0.5528]]])\n"
     ]
    }
   ],
   "source": [
    "print(x_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
